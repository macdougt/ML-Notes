# ML-Notes

### Terms

| Term          | Description|
| ------------- |:-------------|
|Softmax|A form of logistic regression that normalizes an input value into a vector of values that follows a probability distribution whose total sums up to 1. |
|One-Hot as defined for encoding| A group of bits among which the legal combinations of values are only those with a single high (1) bit and all the others low (0)      |
|Dropout|The process of randomly disconnecting nodes from the current layer to the next layer. This process of random disconnects naturally helps the network to reduce overfitting as no one single node in the layer will be responsible for predicting a certain class, object, edge, or corner.|
|Max pooling| A sample-based discretization process. The objective is to down-sample an input representation (image, hidden-layer output matrix, etc.), reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned|
|Batch normalization|A technique for improving the speed, performance, and stability of artificial neural networks and used to normalize the input layer by re-centering and re-scaling|
